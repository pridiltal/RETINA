<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>publications ‚Äì RETINA Lab</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href=".//images/avatar-nobackground.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-dfb324f25d9b1687192fa8be62ac8f9c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="RETINA Lab">
<meta property="og:description" content="">
<meta property="og:image" content="/images/cover.png">
<meta property="og:site_name" content="RETINA Lab">
<meta name="twitter:title" content="RETINA Lab">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="/images/cover.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">RETINA Lab</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./research.html"> 
<span class="menu-text">Research <br> Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./publications.html" aria-current="page"> 
<span class="menu-text">Scholarly <br> Work</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Conferences.html"> 
<span class="menu-text">Conferences &amp; <br> Engagements</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./awards.html"> 
<span class="menu-text">Awards</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./SDG.html"> 
<span class="menu-text">UN SDG <br> Alignment</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://prital.netlify.app/"> 
<span class="menu-text">PI‚Äôs Profile</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#peer-reviewed-publications" id="toc-peer-reviewed-publications" class="nav-link active" data-scroll-target="#peer-reviewed-publications">Peer-Reviewed Publications</a></li>
  <li><a href="#working-papers-preprints" id="toc-working-papers-preprints" class="nav-link" data-scroll-target="#working-papers-preprints">Working Papers &amp; Preprints</a></li>
  <li><a href="#software-tools" id="toc-software-tools" class="nav-link" data-scroll-target="#software-tools">Software &amp; Tools</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="peer-reviewed-publications" class="level2">
<h2 class="anchored" data-anchor-id="peer-reviewed-publications">Peer-Reviewed Publications</h2>
<section id="early-identification-of-deforestation-using-anomaly-detection" class="level4 publication-card">
<h4 class="anchored" data-anchor-id="early-identification-of-deforestation-using-anomaly-detection">Early Identification of Deforestation using Anomaly Detection</h4>
<p><strong>Authors:</strong> N. Wijesinghe, R. Perera, N. Sellahewa, P. D. Talagala<br>
<strong>Published in:</strong> 2023 8th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 2023, pp.&nbsp;1-6<br>
<strong>DOI:</strong> <a href="https://doi.org/10.1109/ICITR61062.2023.10382919">10.1109/ICITR61062.2023.10382919</a></p>
<strong>Abstract:</strong><br>

<div class="abstract-snippet">
<p>Research involving anomaly detection in image streams has seen growth through the years, given the proliferation of high-quality image data in various applications. One such application that is in urgent need of attention is deforestation. Detecting anomalies in this context, however, remains challenging due to the irregular and low-probability nature of deforestation events. <span class="more-text" style="display:none;"> This study introduces two anomaly detection frameworks utilizing machine learning and deep learning for the early detection of deforestation activities in image streams. Furthermore, Explainable AI was used to explain the black box models of the deep learning-based anomaly detection framework. The class imbalance problem, the inter-dependency between the images with time, the lack of available labelled images, a data-driven anomalous threshold, and the trade-off of accuracy while increasing interpretability in the black box optimization methods are some key aspects considered in the model-building process. Our novel framework for anomaly detection in image streams underwent rigorous evaluation using a range of datasets that included synthetic and real-world data, notably datasets related to Amazon‚Äôs forest coverage. The objective of this evaluation was to detect occurrences of deforestation in the Amazon. Several metrics were used to evaluate the performance of the proposed framework.</span></p>
<p><strong>Keywords:</strong> Deep learning, Deforestation, Closed box, Feature extraction, Anomaly detection</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/10382919">üîó View on IEEE Xplore</a> </p>
</div>
<button class="read-more-btn" onclick="toggleReadMore(this)">
Read More
</button>
</section>
<section id="cross-vit-cross-attention-vision-transformer-for-image-duplicate-detection" class="level4 publication-card">
<h4 class="anchored" data-anchor-id="cross-vit-cross-attention-vision-transformer-for-image-duplicate-detection">Cross-vit: Cross-attention vision transformer for image duplicate detection</h4>
<p><strong>Authors:</strong> M. D. N. Chandrasiri and P. D. Talagala<br>
<strong>Published in:</strong> 2023 8th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 2023, pp.&nbsp;1-6<br>
<strong>DOI:</strong> <a href="https://doi.org/10.1109/ICITR61062.2023.10382916">10.1109/ICITR61062.2023.10382916</a></p>
<strong>Abstract:</strong><br>

<div class="abstract-snippet">
<p>Research involving anomaly detection in image streams has seen growth through the years, given the proliferation of high-quality image data in various applications. One such application that is in urgent need of attention is deforestation. Detecting anomalies in this context, however, remains challenging due to the irregular and low-probability nature of deforestation events. <span class="more-text" style="display:none;"> This study introduces two anomaly detection frameworks utilizing machine learning and deep learning for the early detection of deforestation activities in image streams. Furthermore, Explainable AI was used to explain the black box models of the deep learning-based anomaly detection framework. The class imbalance problem, the inter-dependency between the images with time, the lack of available labelled images, a data-driven anomalous threshold, and the trade-off of accuracy while increasing interpretability in the black box optimization methods are some key aspects considered in the model-building process. Our novel framework for anomaly detection in image streams underwent rigorous evaluation using a range of datasets that included synthetic and real-world data, notably datasets related to Amazon‚Äôs forest coverage. The objective of this evaluation was to detect occurrences of deforestation in the Amazon. Several metrics were used to evaluate the performance of the proposed framework.</span></p>
<p><strong>Keywords:</strong> Duplicate Image Detection, Vision Transformers, Attention</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/10382916">üîó View on IEEE Xplore</a> </p>
</div>
<button class="read-more-btn" onclick="toggleReadMore(this)">
Read More
</button>
</section>
<section id="from-crisis-to-opportunity-a-google-trends-analysis-of-global-interest-in-distance-education-tools-during-and-post-the-covid-19-pandemic" class="level4 publication-card">
<h4 class="anchored" data-anchor-id="from-crisis-to-opportunity-a-google-trends-analysis-of-global-interest-in-distance-education-tools-during-and-post-the-covid-19-pandemic">From Crisis to Opportunity: A Google Trends Analysis of Global Interest in Distance Education Tools During and Post the COVID-19 Pandemic</h4>
<p><strong>Authors:</strong> Priyanga Dilini Talagala, Thiyanga S. Talagala<br>
<strong>Published in:</strong> 6th International Conference on Advanced Research Methods and Analytics (CARMA 2024), Valencia, 26-28 June 2024<br>
<strong>DOI:</strong> <a href="https://doi.org/10.4995/CARMA2024.2024.17804">10.4995/CARMA2024.2024.17804</a></p>
<strong>Abstract:</strong><br>

<div class="abstract-snippet">
<p>This study investigated the impact of COVID-19 on global attention towards different distance education tools. We used Google Trend search queries as a proxy to quantify the popularity and public interest in different distance education solutions under 11 subsegments, which include collaboration platforms, online proctoring, and resources for psychosocial support. <span class="more-text" style="display:none;"> The study employs both visual and analytical approaches to analyse global web search queries during and post the COVID-19 pandemic. Through cross-correlation analysis and dynamic time-warping analysis, the study confirms the contemporaneous and lead-lag relationships between COVID-19 and distance education-related search terms. Furthermore, the study highlights the critical role of psychosocial support in promoting the well-being of students and teachers during a pandemic. The study emphasizes the importance of Google footprint analysis in determining the most popular online education resources designed for different educational goals. This feature allows educators to gain insight into prominent distant education options, boosting their online teaching.</span></p>
<p><strong>Keywords:</strong> Online Learning; Online Teaching; Distance Education Solutions; COVID-19 Pandemic; Google Trend Search Queries; Psychosocial Support in Education</p>
<p><a href="https://doi.org/10.4995/CARMA2024.2024.17804">üîó View Conference Paper</a> </p>
</div>
<button class="read-more-btn" onclick="toggleReadMore(this)">
Read More
</button>
</section>
<section id="generalized-meta-framework-for-forecasting" class="level4 publication-card">
<h4 class="anchored" data-anchor-id="generalized-meta-framework-for-forecasting">Generalized Meta Framework for Forecasting</h4>
<p><strong>Authors:</strong> Theepana Govintharajah, Pavadaran Pathmaranjan, Gowsigan Kanagalingam, Priyanga Dilini Talagala</p>
<p><strong>Published in:</strong> 2024 9th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 05-06 December 2024<br>
<strong>DOI:</strong> <a href="https://doi.org/10.1109/ICITR64794.2024.10857715">10.1109/ICITR64794.2024.10857715</a></p>
<strong>Abstract:</strong><br>

<div class="abstract-snippet">
<p>Forecasting tabular time series data has become a challenging task as the time series data has its own unique patterns, and therefore identifying the most suitable modeling approach for a given dataset requires additional investigations and expert knowledge. <span class="more-text" style="display:none;"> In this study, we propose a novel meta framework that utilizes an ensemble approach, combining the models with a high level of performance and efficiency for a given dataset with the aim of proposing a more generalized framework for time series forecasting. In this proposed approach, we use different models from a large pool of candidate models that have the ability to capture unique time series characteristics available in various time series datasets. This approach allows us to get a more robust and generalized framework. By using a variety of forecasting models, including statistics-based prediction models, machine learning-based prediction models, deep learning-based prediction models, and generative modeling, our novel approach ensures broad applicability across various datasets from different application domains. Meta features that describe the structure, complexity, and time series patterns available in a dataset are used to determine the optimal ensemble from a large pool of candidate models for the final prediction process. A hybrid architecture incorporates generative models into the pool, and a stacking approach integrates the predictions of the ensemble‚Äôs member models.</span></p>
<p><strong>Keywords:</strong> Time Series Forecasting, Meta-Learning, Ensemble Modeling, Generative Models, Deep Learning, Machine Learning</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/10857715">üîó View on IEEE Xplore</a> </p>
</div>
<button class="read-more-btn" onclick="toggleReadMore(this)">
Read More
</button>
</section>
<section id="early-disease-outbreak-detection-in-spatio-temporal-data-using-predictive-modeling-and-extreme-value-theory" class="level4 publication-card">
<h4 class="anchored" data-anchor-id="early-disease-outbreak-detection-in-spatio-temporal-data-using-predictive-modeling-and-extreme-value-theory">Early Disease Outbreak Detection in Spatio-Temporal Data Using Predictive Modeling and Extreme Value Theory</h4>
<p><strong>Authors:</strong> E.G.M.A. Senevirathne, Priyanga D. Talagala</p>
<p><strong>Published in:</strong> 2024 9th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 05-06 December 2024<br>
<strong>DOI:</strong> <a href="https://doi.org/10.1109/ICITR64794.2024.10857720">10.1109/ICITR64794.2024.10857720</a></p>
<strong>Abstract:</strong><br>

<div class="abstract-snippet">
<p>Early detection of outbreaks is crucial for reducing their impact on public health. Static manual thresholds have been used for traditional detection methods, which fail to capture extreme events in dynamic transmission patterns. <span class="more-text" style="display:none;"> The aim of this study is to introduce a generalized framework that integrates feature engineering, predictive modeling, and Extreme Value Theory (EVT) for dynamic thresholding in spatio-temporal data. This framework is capable of adapting to different diseases and regions, enabling more accurate outbreak detection across different datasets. Applied to dengue and COVID-19 case data, the proposed method outperformed traditional approaches by achieving higher accuracy, precision, and F1 scores. The EVT-based method provides a more reliable solution for identifying outbreaks in irregularly distributed data, enhancing public health response capabilities.</span></p>
<p><strong>Keywords:</strong> Disease Outbreak Detection, Spatio-Temporal Data, Predictive Modeling, Extreme Value Theory, Public Health</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/10857720">üîó View on IEEE Xplore</a> </p>
</div>
<button class="read-more-btn" onclick="toggleReadMore(this)">
Read More
</button>
</section>
<section id="enhancing-demand-forecasting-in-food-manufacturing-hierarchical-analysis-of-aggregated-and-individual-models" class="level4 publication-card">
<h4 class="anchored" data-anchor-id="enhancing-demand-forecasting-in-food-manufacturing-hierarchical-analysis-of-aggregated-and-individual-models">Enhancing Demand Forecasting in Food Manufacturing: Hierarchical Analysis of Aggregated and Individual Models</h4>
<p><strong>Authors:</strong> Achala Hasini Perera, Priyanga Dilini Talagala, H. Niles Perera, Amila Thibbotuwawa</p>
<p><strong>Published in:</strong> 2024 9th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 05-06 December 2024<br>
<strong>DOI:</strong> <a href="https://doi.org/10.1109/ICITR64794.2024.10857772">10.1109/ICITR64794.2024.10857772</a></p>
<strong>Abstract:</strong><br>

<div class="abstract-snippet">
<p>This study focuses on production planning in the food manufacturing sector using hierarchical forecasting. The selected case for the focal study represents food products with a common main ingredient used in manufacturing. <span class="more-text" style="display:none;"> We employ two scenarios: 1) forecasting aggregated total sales for all products, and 2) forecasting sales for each product separately to calculate the total requirement. We employed three statistical models: autoregressive integrated moving average (ARIMA), exponential smoothing (ETS), and Prophet, and five machine learning models such as linear regression (LR), k-nearest neighbors (KNN), support vector regression (SVR), random forest (RF), and extreme gradient boosting (XGBoost). The key findings highlight that forecasting aggregated total sales for common ingredients outperformed forecasting for each product individually. Further, island-level forecasts were more accurate than district- and distribution-center-level forecasts. XGBoost performed as the best forecasting model, and MinT outperformed as the best reconciliation approach. This study contributes to supply chain strategies when products have common ingredients, optimizing resource allocation and production planning, enhancing operational efficiency in food manufacturing.</span></p>
<p><strong>Keywords:</strong> Demand Forecasting, Food Manufacturing, Hierarchical Forecasting, Machine Learning, Time Series, ARIMA, ETS, Prophet, XGBoost, MinT</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/10857772">üîó View on IEEE Xplore</a> </p>
</div>
<button class="read-more-btn" onclick="toggleReadMore(this)">
Read More
</button>
</section>
<section id="improving-class-imbalance-in-the-classification-of-multi-dimensional-data-interpretable-model-design-and-evaluation" class="level4 publication-card">
<h4 class="anchored" data-anchor-id="improving-class-imbalance-in-the-classification-of-multi-dimensional-data-interpretable-model-design-and-evaluation">Improving Class Imbalance in the Classification of Multi-Dimensional Data: Interpretable Model Design and Evaluation</h4>
<p><strong>Authors:</strong> Gayathri Sivakumar, Chambavy Balasundaram, Vithursan Thevendran, Priyanga Dilini Talagala</p>
<p><strong>Published in:</strong> 2024 9th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 05-06 December 2024<br>
<strong>DOI:</strong> <a href="https://doi.org/10.1109/ICITR64794.2024.10857748">10.1109/ICITR64794.2024.10857748</a></p>
<strong>Abstract:</strong><br>

<div class="abstract-snippet">
<p>This study presents a hybrid approach that combines deep learning techniques with conventional machine learning techniques to address the class imbalance in the classification of multi-dimensional data. <span class="more-text" style="display:none;"> The resulting framework incorporates SHapley Additive exPlanations (SHAP) to evaluate the model predictions based on domain knowledge. It combines Conditional Generative Adversarial Networks (CGANs), Self-Supervised Clustered GANs (SSCGANs), and Variational Autoencoders (VAEs) for the generation of improved synthetic data. This method ensures that model decisions are based on domain-specific knowledge while enabling efficient computation of SHAP values by approximation of complex classifiers using surrogate models. Evaluations show that the suggested method overcomes the shortcomings of current techniques in high-stakes domains and improves classification performance and transparency.</span></p>
<p><strong>Keywords:</strong> Class Imbalance, Multi-Dimensional Data, SHAP, CGAN, SSCGAN, VAE, Explainable AI, Machine Learning, Deep Learning</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/10857748">üîó View on IEEE Xplore</a> </p>
</div>
<button class="read-more-btn" onclick="toggleReadMore(this)">
Read More
</button>
</section>
</section>
<section id="working-papers-preprints" class="level2">
<h2 class="anchored" data-anchor-id="working-papers-preprints">Working Papers &amp; Preprints</h2>
<ol type="1">
<li><p>Chandeepa Pathirana and P. D. Talagala, ‚ÄúDHybrid Feature-Hash Module For Image Duplicate Detection,‚Äù 2025 10th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 2025, (Under Review)</p></li>
<li><p>M.H.D.B Gajakum, M. D. N. Chandrasiri and P. D. Talagala, ‚ÄúDynamic Cluster Specific Ensembles with Explainable AI for Flood Hazard Prediction,‚Äù 2025 10th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka, 2025, (Under Review)</p></li>
<li><p>Wijesinghe, N., Perera, R., Sellahewa, N., &amp; Talagala, P. D. (2024). Anomaly Detection in Image Streams Using Explainable AI (Working Paper). Faculty of Information Technology, University of Moratuwa, Sri Lanka.</p></li>
</ol>
</section>
<section id="software-tools" class="level2">
<h2 class="anchored" data-anchor-id="software-tools">Software &amp; Tools</h2>
<p align="center">
<img src="images/research/clap.png" width="300px">
</p>
<p>Talagala, P. D. (2024). clap: Detecting class overlapping regions in multidimensional data (R package version 0.1.0). <a href="https://doi.org/10.32614/CRAN.package.clap">https://doi.org/10.32614/CRAN.package.clap</a></p>
<p>You can install the <code>clap</code> R package in R using either CRAN or GitHub:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install from CRAN</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"clap"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Or install the development version from GitHub</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("devtools") # if not already installed</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">"pridiltal/clap"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>P. D. Talagala, R. J. Hyndman, and G. Romano, ‚ÄúAnomalyDetection: CRAN Task View: Anomaly Detection,‚Äù GitHub repository, version 2025-10-21, accessed Nov.&nbsp;15, 2025. [Online]. Available: <a href="https://github.com/cran-task-views/AnomalyDetection/">https://github.com/cran-task-views/AnomalyDetection/</a></p>
<p>You can install the <code>AnomalyDetection CRAN Task</code> View in R with a single line using the <code>ctv</code> R package:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the ctv package if you don't have it</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"ctv"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the AnomalyDetection Task View</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">install.views</span>(<span class="st">"AnomalyDetection"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<script>
function toggleReadMore(button) {
  const abstractDiv = button.previousElementSibling;
  const moreText = abstractDiv.querySelector(".more-text");
  if (moreText.style.display === "none") {
    moreText.style.display = "inline";
    button.textContent = "Read Less";
  } else {
    moreText.style.display = "none";
    button.textContent = "Read More";
  }
}
</script>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>